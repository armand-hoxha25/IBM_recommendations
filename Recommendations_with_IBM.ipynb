{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations with IBM\n",
    "\n",
    "In this notebook, you will be putting your recommendation skills to use on real data from the IBM Watson Studio platform. \n",
    "\n",
    "\n",
    "You may either submit your notebook through the workspace here, or you may work from your local machine and submit through the next page.  Either way assure that your code passes the project [RUBRIC](https://review.udacity.com/#!/rubrics/2322/view).  **Please save regularly.**\n",
    "\n",
    "By following the table of contents, you will build out a number of different methods for making recommendations that can be used for different situations. \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Exploratory Data Analysis](#Exploratory-Data-Analysis)<br>\n",
    "II. [Rank Based Recommendations](#Rank)<br>\n",
    "III. [User-User Based Collaborative Filtering](#User-User)<br>\n",
    "IV. [Content Based Recommendations (EXTRA - NOT REQUIRED)](#Content-Recs)<br>\n",
    "V. [Matrix Factorization](#Matrix-Fact)<br>\n",
    "VI. [Extras & Concluding](#conclusions)\n",
    "\n",
    "At the end of the notebook, you will find directions for how to submit your work.  Let's get started by importing the necessary libraries and reading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45993, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...   \n",
       "1      1314.0       healthcare python streaming application demo   \n",
       "2      1429.0         use deep learning for image classification   \n",
       "3      1338.0          ml optimization using cognitive assistant   \n",
       "4      1276.0          deploy your python model as a restful api   \n",
       "\n",
       "                                      email  \n",
       "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7  \n",
       "1  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b  \n",
       "2  b96a4f2e92d8572034b1e9b28f9ac673765cd074  \n",
       "3  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7  \n",
       "4  f01220c46fc92c6e6b161b1849de11faacd7ccb2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import project_tests as t\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# Show df to get an idea of the data\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5148"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['email'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1056, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "1  See the forest, see the trees. Here lies the c...   \n",
       "2  Here’s this week’s news in Data Science and Bi...   \n",
       "3  Learn how distributed DBs solve the problem of...   \n",
       "4  This video demonstrates the power of IBM DataS...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live           0  \n",
       "1  Communicating data science: A guide to present...       Live           1  \n",
       "2         This Week in Data Science (April 18, 2017)       Live           2  \n",
       "3  DataLayer Conference: Boost the performance of...       Live           3  \n",
       "4      Analyze NY Restaurant data using Spark in DSX       Live           4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show df_content to get an idea of the data\n",
    "print(df_content.shape)\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">Part I : Exploratory Data Analysis</a>\n",
    "\n",
    "Use the dictionary and cells below to provide some insight into the descriptive statistics of the data.\n",
    "\n",
    "`1.` What is the distribution of how many articles a user interacts with in the dataset?  Provide a visual and descriptive statistics to assist with giving a look at the number of times each user interacts with an article.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average a user interacts with 8.93 articles\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=sns.distplot(df.groupby('email')['article_id'].count(),axlabel='Number of articles interacted with', bins=200)\n",
    "plt.xlim([0, 15])\n",
    "print(\"On average a user interacts with {} articles\".format(round(df.groupby('email').count().mean()[0],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the median and maximum number of user_article interactios below\n",
    "\n",
    "median_val = df.groupby('email')['article_id'].count().median()# 50% of individuals interact with 3 number of articles or fewer.\n",
    "max_views_by_user =df.groupby('email')['article_id'].count().max() # The maximum number of user-article interactions by any 1 user is 364."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Explore and remove duplicate articles from the **df_content** dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5 duplicate items\n"
     ]
    }
   ],
   "source": [
    "# Find and explore duplicate articles\n",
    "print(\"there are {} duplicate items\".format(df_content.shape[0]-df_content.nunique()['article_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 0 duplicate items\n"
     ]
    }
   ],
   "source": [
    "# Remove any rows that have the same article_id - only keep the first\n",
    "df_content.drop_duplicates(subset='article_id', inplace=True)\n",
    "print(\"there are {} duplicate items\".format(df_content.shape[0]-df_content.nunique()['article_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use the cells below to find:\n",
    "\n",
    "**a.** The number of unique articles that have an interaction with a user.  \n",
    "**b.** The number of unique articles in the dataset (whether they have any interactions or not).<br>\n",
    "**c.** The number of unique users in the dataset. (excluding null values) <br>\n",
    "**d.** The number of user-article interactions in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_articles =df.groupby('article_id').count().shape[0]\n",
    " # The number of unique articles that have at least one interaction\n",
    "total_articles = df_content.shape[0]# The number of unique articles on the IBM platform\n",
    "unique_users = df['email'].nunique()# The number of unique users\n",
    "user_article_interactions =df.shape[0]\n",
    " # The number of user-article interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Use the cells below to find the most viewed **article_id**, as well as how often it was viewed.  After talking to the company leaders, the `email_mapper` function was deemed a reasonable way to map users to ids.  There were a small number of null values, and it was found that all of these null values likely belonged to a single user (which is how they are stored using the function below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1429.0</th>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330.0</th>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431.0</th>\n",
       "      <td>671</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427.0</th>\n",
       "      <td>643</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364.0</th>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title  email\n",
       "article_id              \n",
       "1429.0        937    937\n",
       "1330.0        927    927\n",
       "1431.0        671    671\n",
       "1427.0        643    643\n",
       "1364.0        627    627"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('article_id').count().sort_values(by='email',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.groupby('article_id').count().sort_values(by = 'title',ascending=False).index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_viewed_article_id = '1429.0'# The most viewed article in the dataset as a string with one value following the decimal \n",
    "max_views = 937 # The most viewed article in the dataset was viewed how many times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...        1\n",
       "1      1314.0       healthcare python streaming application demo        2\n",
       "2      1429.0         use deep learning for image classification        3\n",
       "3      1338.0          ml optimization using cognitive assistant        4\n",
       "4      1276.0          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No need to change the code here - this will be helpful for later parts of the notebook\n",
    "# Run this cell to map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you have everything right here! Nice job!\n"
     ]
    }
   ],
   "source": [
    "## If you stored all your results in the variable names above, \n",
    "## you shouldn't need to change anything in this cell\n",
    "\n",
    "sol_1_dict = {\n",
    "    '`50% of individuals have _____ or fewer interactions.`': median_val,\n",
    "    '`The total number of user-article interactions in the dataset is ______.`': df.shape[0],\n",
    "    '`The maximum number of user-article interactions by any 1 user is ______.`': max_views_by_user,\n",
    "    '`The most viewed article in the dataset was viewed _____ times.`': max_views,\n",
    "    '`The article_id of the most viewed article is ______.`': most_viewed_article_id,\n",
    "    '`The number of unique articles that have at least 1 rating ______.`': unique_articles,\n",
    "    '`The number of unique users in the dataset is ______`': unique_users,\n",
    "    '`The number of unique articles on the IBM platform`': total_articles\n",
    "}\n",
    "\n",
    "# Test your dictionary against the solution\n",
    "t.sol_1_test(sol_1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [article_id, title, user_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    sorted_df = df.groupby('title')['article_id'].count().sort_values(ascending=False)\n",
    "    df[df['article_id'].isin(sorted_df.index.to_list()[0:5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use deep learning for image classification',\n",
       " 'insights from new york car accident reports',\n",
       " 'visualize car data with brunel',\n",
       " 'use xgboost, scikit-learn & ibm watson machine learning apis',\n",
       " 'predicting churn with the spss random tree algorithm']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.index[:5].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Rank\">Part II: Rank-Based Recommendations</a>\n",
    "\n",
    "Unlike in the earlier lessons, we don't actually have ratings for whether a user liked an article or not.  We only know that a user has interacted with an article.  In these cases, the popularity of an article can really only be based on how often an article was interacted with.\n",
    "\n",
    "`1.` Fill in the function below to return the **n** top articles ordered with most interactions as the top. Test your function using the tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    sorted_df = df.groupby('title')['article_id'].count().sort_values(ascending=False)\n",
    "    return [str(x) for x in sorted_df.index[:n].to_list()] # Return the top article titles from df (not df_content)\n",
    "\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    sorted_df = df.groupby('article_id')['title'].count().sort_values(ascending=False)\n",
    "    return [str(x) for x in sorted_df.index[:n].to_list()] # Return the top article titles from df (not df_content)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model']\n",
      "['1429.0', '1330.0', '1431.0', '1427.0', '1364.0', '1314.0', '1293.0', '1170.0', '1162.0', '1304.0']\n"
     ]
    }
   ],
   "source": [
    "print(get_top_articles(10))\n",
    "print(get_top_article_ids(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top_5 looks like the solution list! Nice job.\n",
      "Your top_10 looks like the solution list! Nice job.\n",
      "Your top_20 looks like the solution list! Nice job.\n"
     ]
    }
   ],
   "source": [
    "# Test your function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of your three lists from above\n",
    "t.sol_2_test(get_top_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"User-User\">Part III: User-User Based Collaborative Filtering</a>\n",
    "\n",
    "\n",
    "`1.` Use the function below to reformat the **df** dataframe to be shaped with users as the rows and articles as the columns.  \n",
    "\n",
    "* Each **user** should only appear in each **row** once.\n",
    "\n",
    "\n",
    "* Each **article** should only show up in one **column**.  \n",
    "\n",
    "\n",
    "* **If a user has interacted with an article, then place a 1 where the user-row meets for that article-column**.  It does not matter how many times a user has interacted with the article, all entries where a user has interacted with an article should be a 1.  \n",
    "\n",
    "\n",
    "* **If a user has not interacted with an item, then place a zero where the user-row meets for that article-column**. \n",
    "\n",
    "Use the tests to make sure the basic structure of your matrix matches what is expected by the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juggernaut\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    # Fill in the function here\n",
    "    tmpdf = df.copy()\n",
    "    tmpdf['title'].iloc[:]=1\n",
    "    user_item = tmpdf.pivot_table(index = 'user_id', columns = 'article_id',aggfunc = 'max', values='title')\n",
    "    del tmpdf\n",
    "    return user_item # return the user_item matrix \n",
    "\n",
    "user_item = create_user_item_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have passed our quick tests!  Please proceed!\n"
     ]
    }
   ],
   "source": [
    "## Tests: You should just need to run this cell.  Don't change the code.\n",
    "assert user_item.shape[0] == 5149, \"Oops!  The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"Oops!  The number of articles in the user-article matrix doesn't look right.\"\n",
    "assert user_item.sum(axis=1)[1] == 36, \"Oops!  The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"You have passed our quick tests!  Please proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Complete the function below which should take a user_id and provide an ordered list of the most similar users to that user (from most similar to least similar).  The returned result should not contain the provided user_id, as we know that each user is similar to him/herself. Because the results for each user here are binary, it (perhaps) makes sense to compute similarity as the dot product of two users. \n",
    "\n",
    "Use the tests to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_users(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    \n",
    "    '''\n",
    "    # compute similarity of each user to the provided user\n",
    "    user_items_replaced = user_item.replace(to_replace=np.nan, value=0)\n",
    "    users=[]\n",
    "    similarity=[]\n",
    "    vals = user_items_replaced.loc[user_id].values\n",
    "    for user in user_item.index:\n",
    "        users.append(user)\n",
    "        similarity.append(np.dot(vals,user_items_replaced.loc[user].values))\n",
    "    similarity_df = pd.DataFrame({'user_id':users, 'similarity':similarity})\n",
    "\n",
    "    return similarity_df.sort_values(by = 'similarity', ascending = False).index.to_list()\n",
    " # return a list of the users in order from most to least similar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [0, 3932, 22, 3781, 202, 4458, 3869, 130, 4200, 45]\n",
      "The 5 most similar users to user 3933 are: [0, 3932, 22, 3781, 202]\n",
      "The 3 most similar users to user 46 are: [45, 4200, 3781]\n"
     ]
    }
   ],
   "source": [
    "# Do a spot check of your function\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now that you have a function that provides the most similar users to each user, you will want to use these users to find articles you can recommend.  Complete the functions below to return the articles you would recommend to each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use xgboost, scikit-learn & ibm watson machine learning apis',\n",
       " 'using deep learning to reconstruct high-resolution audio',\n",
       " 'gosales transactions for naive bayes model',\n",
       " 'use r dataframes & ibm watson natural language understanding',\n",
       " 'healthcare python streaming application demo',\n",
       " 'build a python app on the streaming analytics service']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_ids = ['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0']\n",
    "#article_ids = [int(float(x)) for x in article_ids]\n",
    "list(set(df[df['article_id'].isin(article_ids)]['title'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Detect Malfunctioning IoT Sensors with Streaming Analytics',\n",
       " 'Communicating data science: A guide to presenting your work',\n",
       " 'This Week in Data Science (April 18, 2017)',\n",
       " 'DataLayer Conference: Boost the performance of your distributed database',\n",
       " 'Analyze NY Restaurant data using Spark in DSX',\n",
       " 'Browsing PostgreSQL Data with Compose',\n",
       " 'Upgrading your PostgreSQL to 9.5',\n",
       " 'Data Wrangling at Slack',\n",
       " 'Data Science Bowl 2017',\n",
       " 'Using Apache Spark to predict attack vectors among billions of users and trillions of events',\n",
       " 'Offline-First iOS Apps with Swift & Cloudant Sync; Part 1: The Datastore',\n",
       " 'Warehousing GeoJSON documents',\n",
       " 'Timeseries Data Analysis of IoT events by using Jupyter Notebook',\n",
       " 'Bridging the Gap Between Python and Scala Jupyter Notebooks',\n",
       " 'Got zip code data? Prep it for analytics. – IBM Watson Data Lab – Medium',\n",
       " 'Apache Spark™ 2.0: Extend Structured Streaming for Spark ML',\n",
       " 'Higher-order Logistic Regression for Large Datasets',\n",
       " 'Compose for MySQL now for you',\n",
       " 'The Greatest Public Datasets for AI – Startup Grind',\n",
       " 'Finding the Mode in PostgreSQL',\n",
       " 'Working interactively with RStudio and notebooks in DSX',\n",
       " 'Mapping for Data Science with PixieDust and Mapbox – IBM Watson Data Lab – Medium',\n",
       " 'Move CSVs into different JSON doc stores',\n",
       " 'Tutorial: How to build and query a Cloudant geospatial index',\n",
       " 'The Conversational Interface is the New Paradigm',\n",
       " 'Creating the Data Science Experience',\n",
       " 'Using Machine Learning to predict parking difficulty',\n",
       " 'Getting The Best Performance With PySpark',\n",
       " 'Deep Forest: Towards An Alternative to Deep Neural Networks',\n",
       " 'Experience IoT with Coursera',\n",
       " 'How open API economy accelerates the growth of big data and analytics',\n",
       " 'Sign up for a free trial in DSX',\n",
       " \"A Kaggler's Guide to Model Stacking in Practice\",\n",
       " 'Using Brunel in IPython/Jupyter Notebooks',\n",
       " 'Top 10 Machine Learning Use Cases: Part 1',\n",
       " 'Gaze Into My Reddit Crystal Ball – IBM Watson Data Lab – Medium',\n",
       " 'Data visualization playbook: The right level of detail',\n",
       " 'Create a Custom Domain for Cloudant Using Cloudflare – IBM Watson Data Lab',\n",
       " 'For Developers: Querying the Cloudant Primary Index',\n",
       " 'Pulling and Displaying ETF Data',\n",
       " 'Ensemble Learning to Improve Machine Learning Results',\n",
       " 'Customizing MongoDB’s Shell with Compact Prompts',\n",
       " \"Getting Started with Compose's ScyllaDB\",\n",
       " 'Deep Learning With Tensorflow Course by Big Data University',\n",
       " 'Uncover Product Insights Hidden in Stack Overflow',\n",
       " 'Start Developing with Spark and Notebooks',\n",
       " 'Q&A Voting App with RethinkDB',\n",
       " 'Install IBM Database Conversion Workbench',\n",
       " 'Data Science Experience Documentation',\n",
       " 'GeoFile: Using OpenStreetMap Data in Compose PostgreSQL - Part II',\n",
       " 'Graph-based machine learning',\n",
       " 'Modern Machine Learning Algorithms',\n",
       " 'Build an app using IBM Graph',\n",
       " 'Introducing Streams Designer',\n",
       " '8 ways to turn data into value with Apache Spark machine learning',\n",
       " 'Predict Flight Delays with Apache Spark MLLib, FlightStats, and Weather Data',\n",
       " 'Introducing the Simple Autocomplete Service',\n",
       " 'Transfer Learning for Flight Delay Prediction via Variational Autoencoders',\n",
       " 'Advancements in the Spark Community',\n",
       " 'How to tame the valley — Hessian-free hacks for optimizing large #NeuralNetworks – Autonomous Agents\\u200a—\\u200a#AI',\n",
       " 'readr 1.0.0',\n",
       " 'Metrics Maven: Window Functions in PostgreSQL',\n",
       " 'Data visualization: The importance of excluding unnecessary details',\n",
       " 'Compose PostgreSQL: Making users and more',\n",
       " 'Predicting gentrification using longitudinal census data',\n",
       " 'InterConnect with us',\n",
       " 'Introducing Cloudant FoodTracker: An Offline-First App',\n",
       " 'Find Mongo Document By ID Using The PHP Library',\n",
       " 'An Introduction to Scientific Python (and a Bit of the Maths Behind It) – NumPy',\n",
       " 'Metrics Maven:  Calculating a Moving Average in PostgreSQL',\n",
       " 'Offline-First Apps with PouchDB',\n",
       " 'Simple Metrics Tutorial Part 1: Metrics Collection -- Code a web analytics app with Node.js and IBM Cloudant',\n",
       " 'Could PostgreSQL 9.5 be your next JSON database?',\n",
       " 'This Week in Data Science (September 27, 2016)',\n",
       " 'The 3 Kinds of Context: Machine Learning and the Art of the Frame',\n",
       " 'Tour the Community in DSX',\n",
       " 'This Week in Data Science (May 2, 2017)',\n",
       " 'Apache Spark @Scale: A 60 TB+ production use case',\n",
       " 'This Week in Data Science (May 16, 2017)',\n",
       " 'Tutorial: How to Cloudant Geospatial in Action',\n",
       " 'Leverage Scikit-Learn Models with Core ML',\n",
       " 'Transform anything into a vector',\n",
       " 'Build a logistic regression model with WML & DSX',\n",
       " \"Compose's first graph database: JanusGraph\",\n",
       " 'Tutorial: How to load Twitter data in IBM dashDB ',\n",
       " 'testthat 1.0.0',\n",
       " 'Metrics Maven: Beyond Average',\n",
       " 'This Week in Data Science (July 26, 2016)',\n",
       " 'Simple Metrics Collector Microservices Edition',\n",
       " 'Top 20 R Machine Learning and Data Science packages',\n",
       " 'New Import for Compose MongoDB',\n",
       " 'Website Engagement Tracking with Elasticsearch',\n",
       " '9 Mistakes to Avoid When Starting Your Career in Data Science',\n",
       " 'Deploy Your PHP Application to Bluemix',\n",
       " 'Armand Ruiz Gabernet, IBM - BigDataNYC #BigDataNYC 2016 #theCUBE',\n",
       " 'This Week in Data Science (December 20, 2016)',\n",
       " 'Improving quality of life with Spark-empowered machine learning',\n",
       " 'This Week in Data Science (November 08, 2016)',\n",
       " 'How to map USA rivers using ggplot2',\n",
       " 'Seven Databases in Seven Days – Day 2: MongoDB',\n",
       " 'Use data assets in a project using IBM Data Catalog',\n",
       " 'How to choose a project to practice data science',\n",
       " 'How to ease the strain as your data volumes rise',\n",
       " 'How to Scale Your Analytics Using R',\n",
       " 'This Week in Data Science (November 15, 2016)',\n",
       " 'Building Offline-First, Progressive Web Apps',\n",
       " 'Data visualization: Function drives design',\n",
       " 'When machine learning matters · Erik Bernhardsson',\n",
       " 'Using Notebooks with PixieDust for Fast, Flexible, and Easier Data Analysis and Experimentation',\n",
       " 'TensorFlow Quick Tips',\n",
       " 'PixieDust: Magic for Your Python Notebook',\n",
       " 'Tidy up your Jupyter notebooks with scripts',\n",
       " 'Building Custom Machine Learning Algorithms With Apache SystemML',\n",
       " 'This Week in Data Science (February 28, 2017)',\n",
       " 'Use all the Databases',\n",
       " 'Finding the user in data science',\n",
       " 'Practical Tutorial on Random Forest and Parameter Tuning in R',\n",
       " 'Apache Spark™ 2.0: Migrating Applications',\n",
       " 'Making the Most of Compose - Customer One Preschool',\n",
       " 'Launch a Spark job using spark-submit',\n",
       " 'A Dynamic Duo – Inside Machine learning – Medium',\n",
       " 'Picking SQL or NoSQL? – A Compose View',\n",
       " 'Watson Machine Learning for Developers',\n",
       " \"What's all the hoopla about graph databases?\",\n",
       " 'Python Machine Learning: Scikit-Learn Tutorial',\n",
       " 'Statistics for Hackers',\n",
       " 'RethinkDB Joinery',\n",
       " 'cloudant/meteor-couchdb',\n",
       " 'Search Faceting from Scratch [Tutorial]',\n",
       " 'DataLayer Conference: Translating Backend Data to Frontend Needs',\n",
       " \"Feature importance and why it's important\",\n",
       " 'Simple Graphing with IPython and\\xa0Pandas',\n",
       " 'Collecting Data Science Cheat Sheets',\n",
       " 'How to Script Painless-ly in Elasticsearch',\n",
       " 'This Week in Data Science (November 01, 2016)',\n",
       " 'Simple CouchDB and Cloudant Backup',\n",
       " 'This Week in Data Science (February 7, 2017)',\n",
       " 'Execute Common HTTP API Commands',\n",
       " 'Best packages for data manipulation in R',\n",
       " 'Designing the UFC Moneyball',\n",
       " 'Emile Baizel & Building a Fintech Bot on MongoDB and Elasticsearch',\n",
       " 'Reddit sentiment analysis in SparkR and CouchDB',\n",
       " 'Neural networks for beginners: popular types and applications',\n",
       " '0 to Life-Changing App: Scala First Steps and an Interview with Jakob Odersky',\n",
       " 'This Week in Data Science (July 12, 2016)',\n",
       " 'Don’t throw more data at the problem! Here’s how to unlock true value from your data lake',\n",
       " 'How to use Db2 Warehouse on Cloud in Data Science Experience notebooks',\n",
       " 'Offline-first QR-code Badge Scanner',\n",
       " 'Search Slack with IBM Graph',\n",
       " 'ibm-cds-labs/hybrid-cloud-tutorial',\n",
       " 'Campus Discounts - Making the Most of Compose (customer)',\n",
       " 'Jupyter Notebook Tutorial',\n",
       " 'How to solve 90% of NLP problems',\n",
       " 'Predicting Flight Cancellations Using Weather Data, Part 3',\n",
       " 'Use dashDB with Tableau',\n",
       " 'Metrics Maven: Calculating an Exponentially Weighted Moving Average in PostgreSQL',\n",
       " 'DataLayer Exposed: Jonas Helfer & Joins Across Databases with GraphQL',\n",
       " 'Data Science of Variable Selection',\n",
       " 'd3heatmap: Interactive heat maps',\n",
       " 'Citizen Scientist finds “Death Star” in SETI data set',\n",
       " 'Location Tracker – Part 2',\n",
       " 'Use the Machine Learning Library in Spark',\n",
       " 'An Introduction to Stock Market Data Analysis with R (Part 1)',\n",
       " 'Portal Powerups and Deleted Deployments',\n",
       " 'Learn TensorFlow and Deep Learning Together and Now!',\n",
       " 'Making the Most of Compose – Customer: Classcraft',\n",
       " 'Push Notifications With MongoDB',\n",
       " 'Introducing Cloudant Local',\n",
       " 'Node.js data science notebooks – IBM Watson Data Lab – Medium',\n",
       " 'RethinkDB and Compose',\n",
       " 'Got a PhD? Struggling To Be a Data Scientist?',\n",
       " 'Deeper into RethinkDB 2.3',\n",
       " 'Simple Data Pipe Connectors',\n",
       " '10 Must Attend Data Science, ML and AI Conferences in 2018',\n",
       " 'Introducing the Simple Search Service: Faceted search API made easy',\n",
       " 'A Way with Words and Code – IBM Watson Data Lab – Medium',\n",
       " 'Top analytics tools in 2016',\n",
       " 'Introducing OpenWhisk: Microservices Made Easy',\n",
       " 'Is PostgreSQL Your Next JSON Database?',\n",
       " 'Power Prototyping with MongoDB and Node-RED',\n",
       " 'Offline First at Offline Camp California',\n",
       " 'Bayesian Regularization for #NeuralNetworks – Autonomous Agents\\u200a—\\u200a#AI',\n",
       " 'Overview of RStudio IDE in DSX',\n",
       " 'Data science expert interview: Holden Karau',\n",
       " 'Improving the ROI of Big Data and Analytics through Leveraging New Sources of Data',\n",
       " 'Location Tracker',\n",
       " 'Geospatial query with Cloudant Search',\n",
       " \"Compose and RethinkDB 2.3's drivers\",\n",
       " 'Foundational Methodology for Data Science',\n",
       " 'Common Excel Tasks Demonstrated in\\xa0Pandas',\n",
       " 'Horizontal Scaling arrives on Compose Enterprise',\n",
       " 'This Week in Data Science (March 28, 2017)',\n",
       " 'Sensor Sensibility at Hull Digital',\n",
       " 'Spark 2.1 and Job Monitoring Available in DSX',\n",
       " 'Data science for real-time streaming analytics',\n",
       " 'Artificial Intelligence, Ethically Speaking – Inside Machine learning – Medium',\n",
       " 'Creating an AWS VPC and Secured Compose MongoDB with Terraform',\n",
       " 'Cloudant Query Grows Up to Handle Ad Hoc Queries',\n",
       " 'New Simple Data Pipe: Easier cloud data movement',\n",
       " 'DataLayer Conference: Storage Wars - The Art Genome Project',\n",
       " 'AI Revolutionizes Industries, not World Domination',\n",
       " 'DataLayer Conference: Keynote with Mitch Pirtle, CapitalOne',\n",
       " 'Analyze open data sets using pandas in a Python notebook',\n",
       " 'Serverless Autocomplete – IBM Watson Data Lab – Medium',\n",
       " 'Charity Majors on Observability & The Glorious Future',\n",
       " \"A Beginner's Guide to Variational Methods\",\n",
       " 'Load XML data into dashDB',\n",
       " 'Compose Tips: Dates and Dating in MongoDB',\n",
       " 'Understanding Mango View-Based Indexes vs. Search-Based Indexes in Cloudant and CouchDB',\n",
       " 'Building a Java EE webapp on IBM Bluemix Using Watson and Cloudant',\n",
       " 'This Week in Data Science (February 14, 2017)',\n",
       " 'Thinky and RethinkDB',\n",
       " 'The Potency of Idempotent with RabbitMQ and MongoDB Upsert',\n",
       " 'Modeling energy usage in New York City',\n",
       " \"Compose's 2016 — All about the database\",\n",
       " 'Data Wrangling with dplyr and tidyr Cheat Sheet',\n",
       " 'Connecting PouchDB to Cloudant on IBM Bluemix',\n",
       " 'Seven Databases in Seven Days – Day 1: RethinkDB',\n",
       " 'Web Picks (week of 28 December 2016)',\n",
       " 'Scaling Offline First with Envoy — Offline Camp',\n",
       " 'A tour of the Redis stars',\n",
       " 'How smart catalogs can turn the big data flood into an ocean of opportunity',\n",
       " 'Authentication for Cloudant Envoy Apps, Part III – IBM Watson Data Lab',\n",
       " 'Using BigDL in DSX for Deep Learning on Spark',\n",
       " 'Using apply, sapply, lapply in R',\n",
       " 'A Visual Explanation of the Back Propagation Algorithm for Neural Networks',\n",
       " \"Move data to the Cloud with dashDB's MoveToCloud script\",\n",
       " 'Bradley Holt on NoSQL (Channel 9)',\n",
       " 'Publish apps that use R analysis with Shiny and dashDB',\n",
       " 'Serverless Data Flow Sequencing with Watson Data API and IBM Cloud Functions',\n",
       " 'Web Picks (week of 23 January 2017)',\n",
       " 'Speed your SQL Queries with Spark SQL',\n",
       " 'Self-service data preparation with IBM Data Refinery',\n",
       " 'Bayesian Nonparametric Models – Stats and Bots',\n",
       " '3 Scenarios for Machine Learning on Multicloud',\n",
       " 'How to enable a Redis cache for PostgreSQL with Entity Framework 6',\n",
       " 'Improving Real-Time Object Detection with YOLO',\n",
       " 'Deep Learning with Data Science Experience',\n",
       " 'Building IoT Apps on Cloudant, with Kiwi Wearables',\n",
       " 'Getting started with GraphFrames in Apache Spark™',\n",
       " 'Spark 1.4 for RStudio',\n",
       " 'I Am Not a Data Scientist – IBM Watson Data Lab',\n",
       " 'Making the Most of Compose – Customer: Omni Labs',\n",
       " 'Mongo Metrics: Calculating the Mode',\n",
       " 'Notebooks: A power tool for data scientists',\n",
       " 'SEIUM Conference and HeartBits Hackathon',\n",
       " 'Offline Verse',\n",
       " 'Document Validation in MongoDB By Example',\n",
       " 'Introducing the new Cloudant query',\n",
       " 'Querying your Cloudant database with SQL – IBM Watson Data Lab – Medium',\n",
       " 'Building Your First Machine Learning System ',\n",
       " 'Data science expert interview: Dez Blanchfield, Craig Brown, David Mathison, Jennifer Shin and Mike Tamir part 2',\n",
       " 'Web Picks (week of 4 September 2017)',\n",
       " 'Lifelong (machine) learning: how automation can help your models get smarter over time',\n",
       " 'Apple, IBM add machine learning to partnership with Watson-Core ML coupling',\n",
       " 'Redis PubSub, Node, and Socket.io',\n",
       " 'xml2 1.0.0',\n",
       " 'Building a Cloudant cluster of Raspberry Pis',\n",
       " 'Open Sourcing 223GB of Driving Data – Udacity Inc',\n",
       " 'etcd 2 to 3: new APIs and new possibilities',\n",
       " 'The Machine Learning Database',\n",
       " 'Replicate a Sample Database',\n",
       " \"IBM's New Builders podcast\",\n",
       " \"December '16 RStudio Tips and Tricks\",\n",
       " 'Introducing spark-cloudant, an open source Spark connector for Cloudant data',\n",
       " 'Redis Configuration Controls',\n",
       " 'Developing IBM Streams applications with the Python API (Version 1.6)',\n",
       " 'Sentiment Analysis of Reddit AMAs',\n",
       " 'Sector Correlations Shiny App',\n",
       " 'This Week in Data Science (September 06, 2016)',\n",
       " 'Learning Statistics on Youtube',\n",
       " 'Configuring Compose Enterprise on Google Cloud Platform',\n",
       " 'Simple data visualization in Apache CouchDB™ – IBM Watson Data Lab – Medium',\n",
       " 'Statistical Bias Types explained (with examples)',\n",
       " 'How to analyze your pipe runs with Bunyan',\n",
       " 'Do More with Compose PostgreSQL using Zapier',\n",
       " 'Integrate dashDB with Excel',\n",
       " 'Work with Data Connections in DSX',\n",
       " 'Deep learning trends and an example',\n",
       " 'How to talk raw Redis',\n",
       " 'Using Lucene search from within CouchDB',\n",
       " \"Analyzing Pet Name Trends with PostgreSQL's crosstabview\",\n",
       " 'Customer: Drone Deploy Conquers the Data Layer',\n",
       " 'Twelve\\xa0ways to color a map of Africa using Brunel',\n",
       " 'Apache Spark 2.0: Machine Learning. Under the Hood and Over the Rainbow.',\n",
       " 'Metrics Maven: Crosstab Revisited - Pivoting Wisely in PostgreSQL',\n",
       " 'Using Cloudant to enhance uploads for IBM Graph',\n",
       " \"Compose for MySQL - A developer's view\",\n",
       " 'This Week in Data Science (January 31, 2017)',\n",
       " 'Writing Data Directly to Cloudant from Slack',\n",
       " 'Elasticsearch Tools & Compose',\n",
       " 'A guide to receptive field arithmetic for Convolutional Neural Networks',\n",
       " 'Understand how replication works',\n",
       " 'Open Data Day, Economic Justice, and Civic Engagement',\n",
       " '10 Common Misconceptions about CouchDB',\n",
       " 'Awesome deep learning papers',\n",
       " 'Making of a Smart Business Chatbot: Part 3',\n",
       " 'Dimensionality Reduction Algorithms',\n",
       " 'Join and enrich data from multiple sources',\n",
       " 'Brunel In Jupyter',\n",
       " \"Introducing Compose's Big Bits\",\n",
       " 'Accessing Relational Databases Using Go',\n",
       " 'Accelerate Your Workflow with DSX',\n",
       " 'Backpropagation — How Neural Networks Learn Complex Behaviors',\n",
       " 'This Week in Data Science (August 30, 2016)',\n",
       " 'MySQL for JSON: Generated Columns and Indexing',\n",
       " 'Moving to Medium',\n",
       " 'DataLayer Conference: Ambry at LinkedIn',\n",
       " 'glynnbird/couchimport',\n",
       " 'Perform Group Facet And Geo Searches with Cloudant',\n",
       " 'Time Series Prediction Using Recurrent Neural Networks (LSTMs)',\n",
       " 'Probabilistic Graphical Models Tutorial\\u200a—\\u200aPart 2 – Stats and Bots',\n",
       " 'On-demand backups with the Compose API and Node.js',\n",
       " 'What is machine learning?',\n",
       " 'Some Random Weekend Reading',\n",
       " 'Neurally Embedded Emojis',\n",
       " 'Leverage Python, SciKit, and text classification for behavioral profiling',\n",
       " 'Authentication for Cloudant Envoy Apps, Part II – IBM Watson Data Lab',\n",
       " 'Use dashDB with Pyspark and Pandas',\n",
       " 'Using shell scripts to control data flows created in Watson applications',\n",
       " 'CouchDB Document Copy and Transform Service',\n",
       " 'Getting started with Elasticsearch and Node.js - part 3',\n",
       " 'Mastering PostgreSQL tools: Filters and Foreign Data Wrappers',\n",
       " 'Manage Object Storage in DSX',\n",
       " 'MyCheatSheets.com',\n",
       " 'Map Your Cloud Data',\n",
       " 'Introducing IBM Graph',\n",
       " 'Enhanced Cloudant Search with Watson Alchemy',\n",
       " 'Now available on IBM Bluemix',\n",
       " 'Introduction to Market Basket Analysis in\\xa0Python',\n",
       " 'Brunel: Imitation is a sincere form of flattery',\n",
       " \"DataLayer Conference: Porting Zendesk's Existing App to GraphQL\",\n",
       " 'Deploying Logshare with Compose and Bluemix',\n",
       " 'A Deep Dive into Offline-First with PouchDB and IBM Cloudant',\n",
       " 'Open Source for Fun, Learning, and Kudos – IBM Watson Data Lab – Medium',\n",
       " 'Creating Notebooks in IBM Data Science Experience',\n",
       " 'Challenges in Deep Learning',\n",
       " 'Generalization in Deep Learning',\n",
       " 'Authenticating Node-RED with JSONWebToken, part 1',\n",
       " 'Get started with Streams Designer by following this roadmap',\n",
       " 'GeoFile: Elasticsearch Geo Queries',\n",
       " 'Metrics Maven: Creating Pivot Tables in PostgreSQL Using Crosstab',\n",
       " 'Load data from the Cloud into dashDB',\n",
       " 'Introducing Meteor Toys 3, Because Toys Make Life Better',\n",
       " 'This Week in Data Science (October 25, 2016)',\n",
       " 'Use the secondary index in Cloudant',\n",
       " 'Fighting Gerrymandering: Using data science to draw fairer congressional districts',\n",
       " 'Announcing DSX Environments in Beta!',\n",
       " 'This Week in Data Science (April 25, 2017)',\n",
       " 'IBM Data Science Experience White paper - SparkR Transforming R into a tool for big data analytics',\n",
       " 'Collect Your Own Fitbit Data with Python',\n",
       " 'Do I need to learn R?',\n",
       " 'How IBM builds an effective data science team',\n",
       " 'sparklyr — R interface for Apache Spark',\n",
       " 'Build the search index in Cloudant',\n",
       " 'Run Shiny Applications in RStudio in DSX',\n",
       " 'Deep Learning, Structure and Innate Priors',\n",
       " 'Lorna Jane Mitchell & Surviving Failure with RabbitMQ',\n",
       " 'Meteor 1.4, MongoDB and Compose - Ready to Oplog',\n",
       " 'Optimizing a marketing campaign: Moving from predictions to actions',\n",
       " 'Intro to Cloudant Query, declarative query API for JSON',\n",
       " 'Location Tracker: Offline first design in Swift',\n",
       " 'DSX: Hybrid Mode',\n",
       " 'Migration from IBM Bluemix Data Connect API (activities) to IBM Watson Data API (data flows)',\n",
       " 'This Week in Data Science (October 18, 2016)',\n",
       " \"Go Serverless with Apex and Compose's MongoDB\",\n",
       " 'Clustering: A Guide for the Perplexed',\n",
       " 'Visualising Data the Node.js Way',\n",
       " 'Snowzilla!',\n",
       " 'Upload data and create Data Frames in Jupyter Notebooks',\n",
       " 'Making the most of Compose - Customer: FATHOM',\n",
       " 'Integrate User Management and Cloudant Query into a Node.js & Cloudant Application',\n",
       " 'Have you had “The Talk” with your chatbot about graph data structures?',\n",
       " 'Working with notebooks in DSX',\n",
       " 'Introducing Cloudant Sync, Open Source Libraries for Mobile',\n",
       " 'Apache SystemML',\n",
       " 'ggplot2 2.2.0 coming soon!',\n",
       " 'Transporter 0.3.0 Released - Transporter Streamlined',\n",
       " 'Use dashDB with Watson Analytics',\n",
       " 'Data Structures Related to Machine Learning Algorithms',\n",
       " 'Analyze Market Trends in Twitter Using Apache Spark, Python, and dashDB',\n",
       " 'A Classification Problem',\n",
       " 'What is text analytics?',\n",
       " 'An interview with Pythonista Katharine Jarmul',\n",
       " 'Continuous Learning on Watson',\n",
       " 'Load geospatial data into dashDB to analyze in Esri ArcGIS',\n",
       " 'Introduction to document conflicts – Part One',\n",
       " 'Why Replication is Awesome',\n",
       " 'Aggregations in MongoDB by Example',\n",
       " 'Apache Spark™ 2.0: Impressive Improvements to Spark SQL',\n",
       " 'Introducing IBM Watson Studio ',\n",
       " 'Building better database bridges with the new Compose Transporter',\n",
       " 'Let the Build Server cf push – IBM Watson Data Lab',\n",
       " 'Authentication for Cloudant Envoy Apps, Part I – IBM Watson Data Lab',\n",
       " 'Seven Databases in Seven Days – Day 4: Cloudant',\n",
       " 'Run DSX Notebooks on Amazon EMR',\n",
       " 'How Compose is Helping Educational Organizations Innovate',\n",
       " 'DataLayer Conference: Rethinking Indexing in Data Stores with Replex',\n",
       " 'Using Apache Spark as a parallel processing framework for accessing REST based data services',\n",
       " 'Predicting The 2016 US Presidential Election',\n",
       " 'Read and Write Data To and From Amazon S3 Buckets in Rstudio',\n",
       " 'The Well Connected Rabbit',\n",
       " 'Metrics Maven: Meet in the Middle - Median in PostgreSQL',\n",
       " 'Show Twitter trends with Spark Streaming and IBM Watson',\n",
       " 'Persistent changes to Spark Config in DSX',\n",
       " 'Window Frames in PostgreSQL',\n",
       " 'This Week in Data Science (November 29, 2016)',\n",
       " 'Cloudant Learning Center',\n",
       " \"Let's Encrypt TLS Certificates\",\n",
       " 'Using GitHub for project control in DSX',\n",
       " \"Using RethinkDB 2.3's user authentication\",\n",
       " '0 to Life-Changing App: New Apache SystemML API on Spark Shell',\n",
       " 'Adoption of machine learning to software failure prediction',\n",
       " 'Join us for Offline Camp',\n",
       " 'Custom Cloudant Replication – IBM Watson Data Lab – Medium',\n",
       " 'Using Machine Learning to Predict Value of Homes On Airbnb',\n",
       " 'Using the Maker Palette in the IBM Data Science Experience',\n",
       " 'IBM Data Catalog Overview',\n",
       " 'PostgreSQL, Backups and everything you need to know',\n",
       " 'Geospatial Nearest Neighbor Query',\n",
       " 'CACHE Table in Apache Spark SQL',\n",
       " 'Navigating SXSW via cognitive chatbot – IBM Watson Data Lab',\n",
       " 'Brunel 2.0 Preview',\n",
       " 'Web application state, à la Dogfight (1983) – IBM Watson Data Lab',\n",
       " 'Create Tables in dashDB',\n",
       " 'Turn Small Data Into Smart Data. Part 3',\n",
       " 'Migrating to Python 3 with pleasure',\n",
       " 'IBM Data Catalog is now generally available',\n",
       " 'Data Science Experience Demo: Modeling energy usage in NYC',\n",
       " 'Why Relational Databases and R?',\n",
       " 'The New Builders podcast Ep 3: Collaboration',\n",
       " 'Making the Most of Compose - Customer DroneDeploy',\n",
       " 'Learn how read/write ops in CouchDB 2.0 work in a cluster',\n",
       " 'A Depth-First Look at Watson Conversation + Gremlin + JanusGraph',\n",
       " 'Customer: iCars Conquers the Data Layer',\n",
       " 'Build a simple data portal with Python and IBM Object Storage',\n",
       " 'Building OHLC Data in PostgreSQL',\n",
       " 'IBM Watson Machine Learning: Get Started',\n",
       " 'Database changes and search indexes that go together like wine & cheese – IBM Watson Data Lab',\n",
       " 'Seven Databases in Seven Days – Day 7: Redis',\n",
       " 'This Week in Data Science (January 24, 2017)',\n",
       " 'Multiplying Microservices',\n",
       " 'Introducing Cloudant Query',\n",
       " 'Load Db2 Warehouse on Cloud data with Apache Spark in DSX',\n",
       " 'Declarative Machine Learning',\n",
       " 'How Marketing Technology Companies Use Compose to Conquer Their Data Layer',\n",
       " 'What’s New in Data Refinery?',\n",
       " 'Get in line! An Intro to Queues and PubSub',\n",
       " 'This Week in Data Science (April 11, 2017)',\n",
       " 'MySQL for your JSON',\n",
       " 'On the Passage of HB2 in North Carolina',\n",
       " 'Change Database Permissions in Cloudant',\n",
       " 'Data Privacy and Governance Update',\n",
       " 'Baby’s first IBM Graph app using Node.js – IBM Watson Data Lab',\n",
       " 'Database Design, Load, and Query from R',\n",
       " 'Make machine learning a reality for your enterprise',\n",
       " 'Bluemix Object Storage Enhanced: Update Precipitation Analysis Sample Notebook',\n",
       " 'Getting Started with Compose and Bluemix',\n",
       " '10 Things I Hate About Your API — Amanda Folson – IBM Watson Data Lab – Medium',\n",
       " 'Hacking vs. Prototyping vs. Production Code – IBM Watson Data Lab – Medium',\n",
       " 'Web Picks - DataMiningApps',\n",
       " 'This Week in Data Science (September 13, 2016)',\n",
       " \"I'd Rather Predict Basketball Games Than Elections: Elastic NBA Rankings\",\n",
       " 'What is Spark?',\n",
       " 'Use IBM Data Science Experience to detect time series anomalies',\n",
       " 'Introduction to Neural Networks, Advantages and Applications',\n",
       " \"Compose's Data Browser comes to Elasticsearch\",\n",
       " 'GeoFile: Converting and importing shapefiles for Compose PostgreSQL and MongoDB',\n",
       " 'What is Hadoop?',\n",
       " 'Connect apps to dashDB',\n",
       " 'What’s new in the Streaming Analytics service on Bluemix',\n",
       " 'Using Cloudant with Node.js',\n",
       " 'Use advanced techniques with the secondary index in Cloudant',\n",
       " 'Intelligent applications - Apache Spark',\n",
       " 'Publish notebooks to GitHub in DSX',\n",
       " 'Gradient Boosting Explained',\n",
       " \"Compose PostgreSQL's new Performance and Extensions views\",\n",
       " 'Markdown for Jupyter notebooks cheatsheet',\n",
       " 'Create a business intelligence and analytics service in Ruby with the dashDB            service',\n",
       " 'Drowning in data sources: How data cataloging could fix your findability problems',\n",
       " 'Optimization for Deep Learning Highlights in 2017',\n",
       " 'Building Mobile Apps At The Geospatial Edge For Shipping, Logistics, & Transportation',\n",
       " 'Using Deep Learning With Keras To Predict Customer Churn',\n",
       " 'Convert IBM Puredata for Analytics to dashDB',\n",
       " 'Compose Enterprise comes to Bluemix',\n",
       " 'A Moving Average Trading Strategy',\n",
       " 'Use Spark R to Load and Analyze Data',\n",
       " 'Get Started With CouchDB Using PHP and Guzzle',\n",
       " 'Getting started with Elasticsearch and Node.js - part 4',\n",
       " 'Amy Unruh & Scaling Out SQL Databases with Spanner',\n",
       " 'Hoodie App Tracker is now deployable to IBM Bluemix',\n",
       " 'This Week in Data Science (May 23, 2017)',\n",
       " 'Web Picks by DataMiningApps',\n",
       " 'This Week in Data Science (October 11, 2016)',\n",
       " 'Python For Loops Explained (Python for Data Science Basics #5)',\n",
       " 'Top 10 Machine Learning Algorithms for Beginners',\n",
       " 'How I used serverless infrastructure to build a large-scale petition system – IBM Watson Data Lab',\n",
       " 'Backups, etcd and etcdtool',\n",
       " 'Bach - The Compose API at your command(line)',\n",
       " 'Let data dictate the visualization',\n",
       " 'The Difference Between AI, Machine Learning, and Deep Learning?',\n",
       " 'Defensive IBM Object Storage Containers – IBM Watson Data Lab – Medium',\n",
       " 'This Week in Data Science (August 02, 2016)',\n",
       " 'Connecting to Compose MongoDB with Java and SSL',\n",
       " 'This Week in Data Science (December 27, 2016)',\n",
       " 'Connection Pooling with MongoDB',\n",
       " 'Conquer Email with Postal and Compose',\n",
       " 'Use dashDB with IBM Embeddable Reporting Service',\n",
       " 'Data science in the cloud',\n",
       " 'Introduction to Graph Databases',\n",
       " 'This Week in Data Science (May 30, 2017)',\n",
       " 'Put a human face on machine learning with WML & DSX',\n",
       " 'Use #Bluemix DashDB and R to solve a Kaggle Competition',\n",
       " 'Search Indexes',\n",
       " 'Coding for Eventual Consistency',\n",
       " 'The Art of Side Effects: Curing Apache Spark Streaming’s Amnesia (Part 1/2)',\n",
       " 'Simple CSV Import For CouchDB – IBM Watson Data Lab – Medium',\n",
       " 'Shaping data with IBM Data Refinery',\n",
       " 'Cloud Data Warehouse Made Easy',\n",
       " 'Better infrastructure maintenance with offline mobile maps',\n",
       " 'Debugging Lua in Redis',\n",
       " 'Learn about Data Science in World of Watson',\n",
       " 'Share the (PixieDust) Magic – IBM Watson Data Lab – Medium',\n",
       " 'Scale a Web App with Microservices and IBM Message Hub',\n",
       " 'Data science platforms are on the rise and IBM is leading the way',\n",
       " 'New Shiny cheat sheet and video tutorial',\n",
       " 'A guest video post',\n",
       " 'A How-to for migrating from etcd 2 to etcd 3',\n",
       " '10 tips on using Jupyter Notebook',\n",
       " 'Create a project and add data using IBM Data Refinery',\n",
       " 'What You Need to Know to Extend NiFi',\n",
       " 'OSCON Europe Talk Review',\n",
       " 'The Two Phases of Gradient Descent in Deep Learning',\n",
       " 'Move over, MatPlotLib – IBM Watson Data Lab – Medium',\n",
       " 'dplyr 0.5.0',\n",
       " 'A Deep Dive into Offline First with PouchDB and IBM Cloudant',\n",
       " 'Embed rich reports in your applications',\n",
       " 'Compose PostgreSQL powers up to 9.6',\n",
       " 'Use cURL to set up replication',\n",
       " 'Convert data from Oracle to dashDB',\n",
       " 'Sentiment Analysis of Reddit AMAs using dashDB and R',\n",
       " 'DataLayer Exposed: Ross Kukulinski & The State Of State In Containers',\n",
       " 'Getting started with Python',\n",
       " 'IBM Analytics at the Esri Partner/Developer Summit',\n",
       " 'Data Visualization with ggplot2 Cheat Sheet',\n",
       " 'Zero to Kubernetes on the IBM Bluemix Container Service',\n",
       " 'Syncing Car Telemetry Data in Real-Time: Ford’s OpenXC API and Cloudant’s Traffic Tamer App',\n",
       " 'Trust in Data Science',\n",
       " 'DataLayer Conference: Scylla, the High-Performance Cassandra-Successor',\n",
       " 'This Week in Data Science (December 13, 2016)',\n",
       " '5-minute Signup Forms with Node-RED and Compose',\n",
       " 'DataLayer Conference: Bootstrapping a Startup using Compose',\n",
       " 'Offline-First iOS Apps with Swift & Cloudant Sync; Part 3',\n",
       " 'Which One to Choose for Your Problem',\n",
       " 'RethinkDB lives, Redis and PostgreSQL futures, FOSDEM, Rust and Wuzz',\n",
       " 'Build a Naive-Bayes Model with WML & DSX',\n",
       " 'Cloudant and Node.js Made Simple with the silverlining Library – IBM Watson Data Lab',\n",
       " \"Let's have some fun with NFL data\",\n",
       " 'Mongo Metrics: Calculating the Mean',\n",
       " 'This Week in Data Science (April 4, 2017)',\n",
       " 'Load Cloudant Data in Apache Spark Using a Scala Notebook',\n",
       " 'Set Up Pre Authenticated cURL',\n",
       " 'Data Connect: Cloud data prep and movement',\n",
       " 'RStudio IDE  Cheat Sheet',\n",
       " 'DT: An R interface to the DataTables library',\n",
       " \"How to watch and wait with Compose's Bach and API\",\n",
       " 'The t-distribution: a key statistical concept discovered by a beer brewery',\n",
       " 'You could be looking at it all wrong',\n",
       " 'Build an iOS 8 App with Bluemix and the MobileFirst Platform for            iOS',\n",
       " 'How can data scientists collaborate to build better business',\n",
       " 'Making the Most of Compose – Case Study: Differential',\n",
       " 'Getting started with Elasticsearch and Node.js - part 1',\n",
       " 'Offline First: What’s in a name? – IBM Watson Data Lab',\n",
       " 'Moving data from DocumentDB to Cloudant or CouchDB – IBM Watson Data Lab',\n",
       " 'Getting started with Elasticsearch and Node.js - part 5',\n",
       " 'The New Builders Ep. 13: All the Data That’s Fit to Analyze',\n",
       " 'Offline and radioactively clean – IBM Watson Data Lab – Medium',\n",
       " 'Use the Primary Index',\n",
       " 'Data-Driven Shopper Insights',\n",
       " 'Why IT Consulting and Developer Services Companies Love Compose',\n",
       " 'Transporter, MongoDB and synchronization',\n",
       " 'GeoFile: How to Transform OpenStreetMap Data into GeoJSON Using GDAL',\n",
       " 'tibble 1.1',\n",
       " 'The million dollar question: Where is my data?',\n",
       " 'This Week in Data Science (December 06, 2016)',\n",
       " 'Tidyverse practice: mapping large European cities',\n",
       " 'Building a business that combines human experts and data science',\n",
       " 'Offline-First iOS Apps with Swift & Cloudant Sync; Part 2',\n",
       " 'tidyr 0.6.0',\n",
       " 'Making the Most of Compose – Customer: Flying Donut',\n",
       " 'Making the Most of Compose - Customer icanmakeitbetter',\n",
       " 'Using NoSQL DBaaS to launch Life Science Software',\n",
       " 'Apache Spark Analytics',\n",
       " 'Upload Files to IBM Data Science Experience Using the Command Line',\n",
       " 'NY Motor Vehicle Accident Analysis',\n",
       " 'Load dashDB Data with Apache Spark',\n",
       " 'Integration Testing Against Real Databases',\n",
       " 'Take a Dip into PostgreSQL Arrays',\n",
       " 'Kibana and Compose Elasticsearch',\n",
       " 'Random forest interpretation – conditional feature contributions',\n",
       " 'Access IBM Analytics for Apache Spark from RStudio',\n",
       " 'How Hyver uses ScyllaDB for API Key Management',\n",
       " 'Manage Your Business with Compose, Odoo, and Bluemix',\n",
       " 'Choosing a Cloudant Library – IBM Watson Data Lab – Medium',\n",
       " 'The 3 Cs of big data',\n",
       " 'How to move data with Transporter - from disk to database',\n",
       " 'Web Picks (December 2017)',\n",
       " 'Recommendation System Algorithms – Stats and Bots',\n",
       " 'A first peek at the next MongoDB',\n",
       " 'Simple Linear Regression? Do It The Bayesian Way',\n",
       " 'Back to basics — Jupyter notebooks',\n",
       " 'Trigger Periodic OpenWhisk Actions – IBM Watson Data Lab – Medium',\n",
       " 'Block chain technology, smart contracts and Ethereum',\n",
       " 'Accessing IBM Graph from Java – IBM Watson Data Lab',\n",
       " 'Making the Most of Compose Enterprise – Customer: ReadMe.io',\n",
       " 'Offline-First mobile apps with IBM Cloudant',\n",
       " 'Three reasons machine learning models go out of sync',\n",
       " 'PixieDust gets its first community-driven feature in 1.0.4',\n",
       " 'Can A.I. Be Taught to Explain Itself?',\n",
       " 'Connecting to RethinkDB with Elixir',\n",
       " 'Define indexes and queries',\n",
       " 'Seven Databases in Seven Days – Day 3: PostgreSQL',\n",
       " 'htmlwidgets: JavaScript data visualization for R',\n",
       " 'Redis Data Browser Now Available in Compose Dashboard',\n",
       " 'Top 6 Questions from our webinar on Top 6 Questions about SQL -> NoSQL Migrations',\n",
       " 'Have you had “The Talk” with your chatbot about graph data structures? – IBM Watson Data Lab',\n",
       " 'Analyze Db2 Warehouse on Cloud data in RStudio in DSX',\n",
       " 'Importing Redis data into Compose Redis',\n",
       " 'Data Warehousing Features, Improvements, and Updates: Introducing the New DashDB',\n",
       " 'Create a Database and Add Documents to Database',\n",
       " 'Taking a Look at Robomongo and Studio 3T with Compose for MongoDB',\n",
       " 'This Week in Data Science (January 17, 2017)',\n",
       " 'Hyperparameter Optimization: Sven Hafeneger',\n",
       " 'Check the status of a replication job',\n",
       " 'Working with Db2 Warehouse on Cloud in Data Science Experience',\n",
       " 'UX Improvements to Cloudant Data-Replication',\n",
       " 'One year as a Data Scientist at Stack Overflow',\n",
       " 'Load JSON from Cloudant database into dashDB',\n",
       " 'Metrics Maven: Calculating a Weighted Average in PostgreSQL',\n",
       " 'Tracking Deployments of Sample Apps',\n",
       " 'Row Level Security with PostgreSQL 9.5',\n",
       " 'Perform sentiment analysis with LSTMs, using TensorFlow',\n",
       " 'Persisting Data for a Smarter Chatbot',\n",
       " 'BigInsights on Cloud for Analysts',\n",
       " \"H2O With IBM's Data Science Experience (DSX)\",\n",
       " 'How to Perform a Logistic Regression in R',\n",
       " 'Importing Game of Thrones Data into Cloudant with the Simple Search Service',\n",
       " 'Getting started with Apache Mahout',\n",
       " 'Compose Enterprise Reloaded',\n",
       " 'Analysing Cloudant JSON in RunKit JavaScript Notebooks – IBM Watson Data Lab',\n",
       " 'GeoFile: Everything in the Radius with MongoDB Geospatial Queries',\n",
       " 'Analyzing streaming Data from Kafka Topics',\n",
       " 'Mongo to Mongo Data Moves with NiFi',\n",
       " 'Create a connection and add it to a project using IBM Data Refinery',\n",
       " 'MongoDB and Ransomware',\n",
       " 'Create a project for Watson Machine Learning in DSX',\n",
       " 'Deep Learning Achievements Over the Past Year ',\n",
       " 'Why a managed database from Compose?',\n",
       " 'Automating web analytics through Python',\n",
       " 'Discover, catalog and govern data with IBM Data Catalog',\n",
       " 'Create a replication job',\n",
       " '21 Must-Know Data Science Interview Questions and Answers',\n",
       " 'Build Deep Learning Architectures With Neural Network Modeler',\n",
       " 'Find the User in Data Science ',\n",
       " 'DataLayer Conference: Partial Indexing for Improved Query Performance',\n",
       " 'Get social with your notebooks in DSX',\n",
       " 'Integrate dashDB and Informatica Cloud',\n",
       " 'Imitation Learning in Tensorflow (Hopper from openAI gym)',\n",
       " 'Shiny: a data scientist’s best friend',\n",
       " '70 Amazing Free Data Sources You Should Know',\n",
       " 'Calculate moving averages on real time data with Streams Designer',\n",
       " 'Libraries and Tutorials',\n",
       " 'SQLPro for Postgres and Keylord for Redis',\n",
       " 'Predict Chronic Kidney Disease Using SPSS Modeler Flows',\n",
       " 'Simulating E.T. – Or: how to insert individual files into object storage from within a map function in Apache Spark',\n",
       " 'Webinar: April 11 - Thinking inside the box: you can do that inside a data frame?!',\n",
       " 'Cloudant Sync for iOS v1.0 is released',\n",
       " 'Package Development with devtools  Cheat Sheet',\n",
       " 'Spark SQL - Rapid Performance Evolution',\n",
       " 'This Week in Data Science',\n",
       " 'How the Circle Line rogue train was caught with data',\n",
       " 'Real-Time Sentiment Analysis of Twitter Hashtags with Spark (+ PixieDust)',\n",
       " 'Easy JSON Loading and Social Sharing in DSX Notebooks',\n",
       " 'Store Tweets Using Bluemix, Node-RED, Cloudant, and dashDB',\n",
       " 'flexdashboard: Interactive dashboards for R',\n",
       " 'Working with data flows using  Watson Data APIs',\n",
       " 'Score a Predictive Model Built with IBM SPSS Modeler, WML & DSX',\n",
       " 'Easy Access to All Points of Interest Data – IBM Watson Data Lab – Medium',\n",
       " 'Offline Sync for Progressive Web Apps – IBM Watson Data Lab – Medium',\n",
       " 'Improved Performance for Redis Cache Mode on Compose',\n",
       " 'Simple Search Service',\n",
       " 'Connecting R and Compose PostgreSQL',\n",
       " '15 Page Tutorial for R',\n",
       " 'Better together: SPSS and Data Science Experience',\n",
       " 'Predict temperatures using dashDB, Python, and R',\n",
       " 'Excel files: Loading from Object Storage — Python',\n",
       " 'Mongo Metrics: Finding a Happy Median',\n",
       " 'DataLayer Conference: Online Schema Migrations for MySQL Using gh-ost',\n",
       " 'Visualizing Stripe Data With Chartio',\n",
       " 'Metrics Maven: Calculating a Weighted Moving Average in PostgreSQL',\n",
       " 'Magical Markov Chains',\n",
       " 'Missing data conundrum: Exploration and Imputation Techniques',\n",
       " 'Access an On-Premises DB2 Data Server from the Bluemix Cloud',\n",
       " 'Building CouchApps',\n",
       " 'Use Aginity Workbench for IBM dashDB',\n",
       " 'Word2Vec in Data Products',\n",
       " 'This Week in Data Science (August 16, 2016)',\n",
       " 'Cloudant <3 Apache CouchDB™ 2.0',\n",
       " 'Load and analyze public data sets in DSX',\n",
       " \"A Quick Guide to Redis 3.2's Geo Support\",\n",
       " 'Using PostgreSQL through SQLAlchemy',\n",
       " 'Cross-Database Querying in Compose PostgreSQL',\n",
       " 'GeoFile: Using OpenStreetMap Data in Compose PostgreSQL - Part I',\n",
       " 'PostgreSQL connection limit control',\n",
       " 'A Survey of Books about Apache Spark™',\n",
       " \"For AI to Get Creative, It Must Learn the Rules--Then How to Break 'Em\",\n",
       " 'Simple OAuth With MongoDB & MySQL',\n",
       " 'Index Array Elements & Query JSON',\n",
       " 'The Database Tool for Elixir and Phoenix',\n",
       " 'Data Migration & Transformation Tools',\n",
       " 'Data Visualization Playbook: Telling the Data Story',\n",
       " 'The power of machine learning in Spark',\n",
       " 'Visual Information Theory ',\n",
       " '10 Essential Algorithms For Machine Learning Engineers',\n",
       " 'NIPS 2016 — Day 2 Highlights',\n",
       " 'This Week in Data Science (March 7, 2017)',\n",
       " 'May 2016: Scripts of the Week',\n",
       " 'From Python Nested Lists to Multidimensional numpy Arrays',\n",
       " 'The Most Popular Search Term at SXSW, According to Our Chatbot',\n",
       " 'PixieDust 1.0 is here! – IBM Watson Data Lab',\n",
       " 'Developing for the IBM Streaming Analytics service',\n",
       " 'You may get pwned! At least protect passwords with bcrypt.',\n",
       " 'Rapidly build Machine Learning flows with DSX',\n",
       " 'Mobile Apps Offline and Online',\n",
       " 'Asynchronous Joins Using RabbitMQ',\n",
       " 'Making Sense of the Bias / Variance Trade-off in (Deep) Reinforcement Learning',\n",
       " 'This Week in Data Science (September 20, 2016)',\n",
       " 'PouchDB: the Swiss Army Knife of databases – IBM Watson Data Lab – Medium',\n",
       " 'Simple Service Registry',\n",
       " 'Store Result Sets with Materialized Views in PostgreSQL',\n",
       " '10 pieces of advice to beginner data scientists',\n",
       " 'Easy Frontends for Simple Search API Using GoT Data',\n",
       " 'Deploying a Full Stack Node.js Application to IBM Bluemix',\n",
       " 'Seven Databases in Seven Days – a Cloud Data Services journey',\n",
       " 'Spark-based machine learning tools for capturing word meanings',\n",
       " 'Talking ScyllaDB with CTO Avi Kivity',\n",
       " 'httr 1.2.0',\n",
       " 'Storing Network Addresses using PostgreSQL',\n",
       " 'GeoFile: Spatial Reference Systems and Databases',\n",
       " 'Hurricane How-To',\n",
       " 'Introducing Cloudant Geospatial',\n",
       " 'Build a Predictive Analytic Model',\n",
       " '“Schemas” in CouchDB',\n",
       " 'Sharing non-public data in Jupyter notebooks – IBM Watson Data Lab – Medium',\n",
       " 'Move a toy car with your mind',\n",
       " 'Getting started with Elasticsearch and Node.js - part 2',\n",
       " 'Mobile Web Apps with PouchDB, AngularJS, Node.js and IBM Cloudant',\n",
       " 'Working with on-premises databases — Step by Step',\n",
       " 'A glimpse inside the mind of a data scientist',\n",
       " 'Are Your Predictive Models like Broken Clocks?',\n",
       " 'SETI data, publicly available, from IBM',\n",
       " 'Variational auto-encoder for \"Frey faces\" using keras',\n",
       " 'From Machine Learning to Learning Machine (Dinesh Nirmal)',\n",
       " 'Load data into RStudio for analysis in DSX',\n",
       " 'Tidy Data In Python',\n",
       " 'Announcing the Data Browser for JanusGraph',\n",
       " 'Making data science a team sport',\n",
       " 'Building Secure Distributed Javascript Microservices with RabbitMQ and SenecaJS',\n",
       " 'Python If Statements Explained (Python For Data Science Basics #4)',\n",
       " 'Powering social feeds and timelines with Elasticsearch',\n",
       " 'Easier Java connections to MongoDB at Compose',\n",
       " 'Export Cloudant JSON as CSV, RSS, or iCal',\n",
       " 'BigInsights Sample Scripts',\n",
       " 'Caching Cloudant Requests with cachemachine',\n",
       " 'Authenticating Node-RED using JSONWebToken, part 2',\n",
       " 'PostGraphQL: PostgreSQL meets GraphQL',\n",
       " 'Your own weather forecast in a Python notebook',\n",
       " 'Making of a Smart Business Chatbot: Part 2',\n",
       " 'Governance overview for IBM Data Catalog',\n",
       " 'Connecting applications to Compose for MySQL',\n",
       " 'Database Management Tools and Compose for MySQL',\n",
       " 'Empirical Bayes for multiple sample sizes',\n",
       " 'Effectively Using\\xa0Matplotlib',\n",
       " 'Handling Failure Successfully in RabbitMQ – IBM Watson Data Lab',\n",
       " '10 Data Science, Machine Learning and AI Podcasts You Must Listen To',\n",
       " 'Interactive time series with dygraphs',\n",
       " 'Getting Connected with RabbitMQ and Elasticsearch',\n",
       " 'Cloud Data Services',\n",
       " 'Quick Guide to Build a Recommendation Engine in Python',\n",
       " \"Java and Let's Encrypt certificates\",\n",
       " 'Compose RabbitMQ now out of beta',\n",
       " 'Command-line tools for Cloudant and CouchDB',\n",
       " \"Building Instant RESTFul API's with MongoDB and RESTHeart\",\n",
       " '10 Powerful Features on Watson Data Platform, No Coding Necessary',\n",
       " 'On calculating AUC',\n",
       " 'A Dramatic Tour through Python’s Data Visualization Landscape (including ggplot and Altair)',\n",
       " 'Moving data from DynamoDB to Cloudant or CouchDB – IBM Watson Data Lab',\n",
       " 'Reintroducing the Simple Search Service',\n",
       " 'Blogging without the hosting – IBM Watson Data Lab',\n",
       " 'Eye Candy for Cloudant – IBM Watson Data Lab – Medium',\n",
       " 'Machine Learning for the Enterprise',\n",
       " 'Sentiment Analysis of Twitter Hashtags',\n",
       " 'Connecting to Compose for MySQL',\n",
       " 'Simple Website Metrics',\n",
       " 'Making the most of Compose: Customer case study with Human Design',\n",
       " 'Machine Learning for everyone',\n",
       " 'Collaborate on projects in DSX',\n",
       " 'This Week in Data Science (August 23, 2016)',\n",
       " 'Interview: Christopher Quinones on the newest graph database, JanusGraph',\n",
       " 'Use the Machine Learning Library',\n",
       " 'Environment variables, or keeping your secrets secret in a Node.js app – IBM Watson Data Lab',\n",
       " 'Getting the distance using Redis and PostgreSQL',\n",
       " 'Machine Learning Exercises In Python, Part 1',\n",
       " 'Generative Adversarial Networks (GANs)',\n",
       " 'Add custom Alexa skills with OpenWhisk and Cloudant – IBM Watson Data Lab',\n",
       " 'What I learned at PyCon and Spark Summit',\n",
       " 'Offline First FOMO',\n",
       " 'Girl Develop It Leadership Summit Recap',\n",
       " 'Building JavaScript Microservices with SenecaJS and Compose',\n",
       " 'Avoid Storing Data Inside \"Admin\" When Using MongoDB',\n",
       " 'Keeping data warehouse infrastructure out of your way',\n",
       " 'Using RStudio in IBM Data Science Experience',\n",
       " 'Plug-In to the Cloudant Node.js Library v1.5',\n",
       " 'Node-RED',\n",
       " 'Code Walkthrough of IBM MobileFirst Platform on Bluemix Hosted Acme Apparel Application',\n",
       " 'What is SMOTE in an imbalanced class setting (e.g. fraud detection)?',\n",
       " \"Building Secure Instant API's with RESTHeart and Compose\",\n",
       " 'Add data assets to a catalog using IBM Data Catalog',\n",
       " 'This Week in Data Science (August 09, 2016)',\n",
       " 'Analyzing Salesforce Data with Looker: A Salesforce BI solution with dashDB, Cloudant, and Looker',\n",
       " 'Getting Started with Elasticsearch using Compose',\n",
       " 'Turn Small Data Into Smart Data. Part 1',\n",
       " 'Voice of InterConnect – IBM Watson Data Lab',\n",
       " 'Machine Learning and the Science of Choosing',\n",
       " 'App Store gives hope to Indie Developers Again?',\n",
       " 'Build SQL Queries in a Scala notebook using Apache Spark',\n",
       " 'This Week in Data Science (October 05, 2016)',\n",
       " 'The Center of Your Data Universe',\n",
       " 'Seven Databases in Seven Days – Day 5: etcd',\n",
       " 'Leverage dashDB in Cognos Business Intelligence',\n",
       " 'Authorized curl, a.k.a acurl',\n",
       " 'Access Documentation and Support Resources',\n",
       " 'Querying Your PouchDB Database with SQL – IBM Watson Data Lab – Medium',\n",
       " 'Aspiring Data Scientists! Start to learn Statistics with these 6 books!',\n",
       " 'Use the Cloudant-Spark connector in Python notebook',\n",
       " 'Optimizing MongoDB Queries with Elasticsearch',\n",
       " 'Pearson correlation aggregation on SparkSQL',\n",
       " 'Navigating NoSQL',\n",
       " 'Schema migrations with Alembic, Python and PostgreSQL',\n",
       " 'Humans vs. Apache Spark: Building our Rock-Paper-Scissors game',\n",
       " 'Example Chrome Extensions Using PouchDB',\n",
       " 'Create a serverless, Watson-powered chatbot for your business',\n",
       " 'Scaling an Existing PHP App with RabbitMQ',\n",
       " 'Best Practices for Custom Models in Watson Visual Recognition',\n",
       " 'Making Data Pretty in PostgreSQL',\n",
       " 'Enjoy Python 3.5 in Jupyter Notebooks',\n",
       " 'Running PouchDB in a Web Worker',\n",
       " 'R Markdown Reference Guide',\n",
       " 'Analyze Starcraft II replays with Jupyter Notebooks',\n",
       " 'Build Scalable Webhooks with a Queue and Workers Setup – IBM Watson Data Lab',\n",
       " 'MapReduce explained',\n",
       " 'Cleaning the swamp: Turn your data lake into a source of crystal-clear insight',\n",
       " 'Time Series Analysis Using Max/Min and Neuroscience',\n",
       " 'Introduction to Compose for MongoDB',\n",
       " 'This Week in Data Science (February 21, 2017)',\n",
       " 'Analyze traffic data from the city of San Francisco',\n",
       " 'Turn Small Data Into Smart Data. Part 2',\n",
       " 'Webizing your database with Linked Data in JSON-LD on Cloudant',\n",
       " 'How to write the first for loop in R',\n",
       " 'An IBM Graph client library for Node.js',\n",
       " 'Stacking Multiple Custom Models in Watson Visual Recognition',\n",
       " 'Overfitting in Machine Learning: What It Is and How to Prevent It',\n",
       " 'Sample Python Notebook: Precipitation Analysis',\n",
       " 'Load data from the desktop into dashDB',\n",
       " 'Faster Performance with Unlogged Tables in PostgreSQL',\n",
       " 'NIPS 2016 — Day 1 Highlights',\n",
       " 'Statistical Bias Types explained',\n",
       " 'Building an Ordering Application with Watson AI and PostgreSQL: Part 1',\n",
       " '10 Data Science Podcasts You Need To be Listening To Right Now',\n",
       " 'Do you know why Compose proxies database connections?',\n",
       " 'Probabilistic Graphical Models Tutorial\\u200a—\\u200aPart 1 – Stats and Bots',\n",
       " 'Web Picks (week of 2 October 2017)',\n",
       " 'Blogging With Brunel',\n",
       " 'Building an Ordering Application with Watson AI and PostgreSQL: Part II',\n",
       " 'Don’t overlook simpler techniques and algorithms',\n",
       " 'Use NiFi to Lessen the Friction of Moving Data',\n",
       " 'Perform market basket analysis using dashDB and R',\n",
       " 'Forgetting the Past to Learn the Future: Long Short-Term Memory Neural Networks for Time Series Prediction',\n",
       " 'Use All the Databases – Part 2',\n",
       " 'Mobile App Webinar Demo',\n",
       " 'Connecting PHP to Compose for MySQL on Bluemix',\n",
       " 'Interactive Web Apps with shiny Cheat Sheet',\n",
       " 'Breaking the 80/20 rule: How data catalogs transform data scientists’ productivity',\n",
       " 'Use the Machine Learning Library in IBM Analytics for Apache Spark',\n",
       " 'GeoJSON Database with Cloudant + Mapbox',\n",
       " 'Seven Databases in Seven Days – Day 6: IBM Graph',\n",
       " 'A guide to convolution arithmetic for deep learning',\n",
       " 'Simple Metrics Tutorial Part 2',\n",
       " 'Neural Language Modeling From Scratch (Part 1)',\n",
       " 'tidyr 0.4.0',\n",
       " 'Introducing the Simple Notification Service',\n",
       " 'PouchDB, the In-Browser Database That Replicates',\n",
       " 'Open Crime Data, Free for All',\n",
       " 'An Attempt to Understand Boosting Algorithm(s)',\n",
       " 'Query The Search Index',\n",
       " 'The Random Forest Algorithm ',\n",
       " 'Jupyter (IPython) notebooks features',\n",
       " 'Build Spark SQL Queries',\n",
       " 'Making of a Smart Business Chatbot: Part 1',\n",
       " 'Cloudant Search Geo Example',\n",
       " 'Working With IBM Cloud Object Storage In Python',\n",
       " 'Using Machine Learning to Predict Baseball Injuries',\n",
       " 'Search Lobbyist Disclosures',\n",
       " 'Building a dynamic configuration service with etcd and Python',\n",
       " 'Diff your databases with couchdiff – IBM Watson Data Lab – Medium',\n",
       " 'Land Stripe data in IBM dashDB cloud data warehouse',\n",
       " 'Use the new Cloudant query',\n",
       " 'IBM Cloudant overview, NoSQL database-as-a-service',\n",
       " 'Tell Me Something I Don’t Know – IBM Watson Data Lab – Medium',\n",
       " 'Watson Speech-to-Text Services — tl;dr need not apply',\n",
       " 'Everything in the Radius with PostGIS',\n",
       " 'Visualizing Compose PostgreSQL Data with Leftronic',\n",
       " 'Customer: Interloop - Making the Most of Compose',\n",
       " 'Compose for MySQL and Compose for ScyllaDB: the new Compose databases on Bluemix',\n",
       " 'DataLayer Exposed: Antonio Chavez & Why We Left MongoDB',\n",
       " 'Build SQL queries with Apache Spark in DSX',\n",
       " 'Talent vs Luck: the role of randomness in success and failure',\n",
       " 'Reading & Writing',\n",
       " 'Time Series Anomaly Detection Algorithms – Stats and Bots',\n",
       " 'tidyr 0.5.0',\n",
       " 'How to use version control (GitHub) in RStudio within DSX?',\n",
       " 'Short-Notice Serverless Conference',\n",
       " 'Pseudo-labeling a simple semi-supervised learning method',\n",
       " 'Workflow in R',\n",
       " 'Load Cloudant Data in Apache Spark Using a Python Notebook',\n",
       " 'Making data cleaning simple with the Sparkling.data library',\n",
       " 'Unstructured and structured data versus repetitive and non-repetitive',\n",
       " 'Who limits the rate-limiter? – IBM Watson Data Lab – Medium',\n",
       " 'Formatted SQL in Python with Psycopg’s Mogrify',\n",
       " 'Deep Learning From Scratch I: Computational Graphs',\n",
       " 'A New Version of DT (0.2) on CRAN',\n",
       " 'A Fast On-Disk Format for Data Frames for R and Python, powered by Apache Arrow',\n",
       " 'Interview with Sean Li, New Apache Spark™ Committer',\n",
       " 'Discover hidden Facebook usage insights',\n",
       " 'Extract and export dashDB data to a CSV file',\n",
       " 'Customer: ReadMe Conquering the Data Layer',\n",
       " 'New at Compose: Horizontal Scaling for Redis and more scaling control',\n",
       " 'Big data is better data',\n",
       " 'What is SystemML? Why is it relevant to you?',\n",
       " 'Apache Spark SQL Analyzer Resolves Order-by Column',\n",
       " 'Why Developer Experience Matters at Cloud Expo 2015',\n",
       " 'Shiny 0.12: Interactive Plots with ggplot2',\n",
       " 'Why even a moth’s brain is smarter than an AI',\n",
       " 'Simple Data Pipe connectors',\n",
       " 'A Plethora of Open Data Repositories (i.e., thousands!)',\n",
       " 'Leaflet: Interactive web maps with R',\n",
       " 'BigInsights on Cloud for Data Scientists',\n",
       " 'Brunel interactive visualizations in Jupyter notebooks',\n",
       " 'Using DSX notebooks to analyze GitHub data',\n",
       " 'Understanding empirical Bayes estimation (using baseball statistics)',\n",
       " 'INTERVIEW: LEVERAGING TECHNOLOGY, AND D3.JS',\n",
       " 'Beyond Parallelize and Collect',\n",
       " 'Data visualization with R: Scrum metrics',\n",
       " 'How to get backups with the Compose API and Node.js',\n",
       " 'Our first Offline First camp <3',\n",
       " 'Data Visualization Playbook: Revisiting the Basics',\n",
       " 'Faster Operations with the jsonb Data Type in PostgreSQL',\n",
       " 'ML Algorithm != Learning Machine',\n",
       " 'Shiny 0.13.0',\n",
       " 'FlightPredict II: The Sequel  – IBM Watson Data Lab',\n",
       " 'Launching RESTHeart into Production',\n",
       " 'Defensive coding in Map/Index functions',\n",
       " 'Create a project in DSX',\n",
       " 'Recent trends in recommender systems',\n",
       " 'This Week in Data Science (November 22, 2016)',\n",
       " 'The Data Science Process',\n",
       " 'Using couchimport to load JSON data into Cloudant',\n",
       " 'Apache Spark as the New Engine of Genomics',\n",
       " 'Session Recap: Save the World with Offline First – IBM Watson Data Lab',\n",
       " 'Making the Most of Compose: Customer C2G Consulting',\n",
       " 'logshare',\n",
       " 'Super Fast String Matching in Python',\n",
       " 'Identify Useful HTTP API Tools',\n",
       " 'Redis, Go, & How to Build a Chat Application',\n",
       " 'The Data Processing Inequality',\n",
       " 'A Day in the Life of a Data Engineer',\n",
       " 'R for Data Science',\n",
       " 'Realtime Infrastucture Made Simple – IBM Watson Data Lab',\n",
       " 'Accessing DB2 on-prem databases from IBM Bluemix cloud',\n",
       " 'Mastering Redis high-availability and blocking connections',\n",
       " 'This Week in Data Science (January 10, 2017)',\n",
       " 'Bach Updated and Support Streamlined',\n",
       " 'Building a MobileFirst App on IBM Bluemix',\n",
       " 'Configuring the Apache Spark SQL Context',\n",
       " 'Using Query String Queries in Elasticsearch',\n",
       " 'Visualizing weather data as a PixieApp – IBM Watson Data Lab – Medium',\n",
       " '5 Practical Use Cases of Social Network Analytics: Going Beyond Facebook and Twitter',\n",
       " 'Apache Spark: Upgrade and speed-up your analytics',\n",
       " 'GeoFile: PostGIS and Raster Data',\n",
       " 'From PureData System for Analytics to a dashDB Cloud Data Warehouse',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content['doc_full_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    # Your code here\n",
    "    article_ids = [float(x) for x in article_ids]\n",
    "    return list(set(df[df['article_id'].isin(article_ids)]['title'].to_list()))\n",
    "    # Return the article names associated with list of article ids\n",
    "\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the doc_full_name column in df_content)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    # Your code here\n",
    "    user_row = user_item[user_item.index==user_id]\n",
    "    ids= []\n",
    "    for val, col in zip(user_row.values[0],user_row.columns):\n",
    "        if val ==1.0:\n",
    "            ids.append(str(col))    \n",
    "    article_names = get_article_names(ids)\n",
    "    return ids, article_names # return the ids and names\n",
    "\n",
    "\n",
    "def user_user_recs(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    similar_users = find_similar_users(user_id)\n",
    "    user_article_ids = get_user_articles(user_id)[0]\n",
    "    recs = []\n",
    "    n_user=1\n",
    "    nrecs  = 0\n",
    "    cond = True\n",
    "    while cond:\n",
    "        current_ids=get_user_articles(similar_users[n_user])[0]\n",
    "        u1 = set(user_article_ids)\n",
    "        u2 = set(current_ids)\n",
    "        setdif= list(u2 - u1)\n",
    "        for e in setdif:\n",
    "            recs.append(e)\n",
    "            nrecs = nrecs+1\n",
    "            if nrecs == m:\n",
    "                cond = False\n",
    "                break\n",
    "        n_user = n_user+1\n",
    "        \n",
    "    return recs # return your recommendations for this user_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you passed all of our tests!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Test your functions here - No need to change this code - just run this cell\n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"If this is all you see, you passed all of our tests!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Now we are going to improve the consistency of the **user_user_recs** function from above.  \n",
    "\n",
    "* Instead of arbitrarily choosing when we obtain users who are all the same closeness to a given user - choose the users that have the most total article interactions before choosing those with fewer article interactions.\n",
    "\n",
    "\n",
    "* Instead of arbitrarily choosing articles from the user where the number of recommended articles starts below m and ends exceeding m, choose articles with the articles with the most total interactions before choosing those with fewer total interactions. This ranking should be  what would be obtained from the **top_articles** function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "                    \n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where \n",
    "                    highest of each is higher in the dataframe\n",
    "     \n",
    "    '''\n",
    "    # Your code here\n",
    "    user_items_replaced = user_item.replace(to_replace=np.nan, value=0)\n",
    "    users=[]\n",
    "    similarity=[]\n",
    "    n_articles = []\n",
    "    vals = user_items_replaced.loc[user_id].values\n",
    "    for user in user_item.index:\n",
    "        users.append(user)\n",
    "        similarity.append(np.dot(vals,user_items_replaced.loc[user].values))\n",
    "        n_articles.append(np.sum(user_items_replaced.loc[user].values))\n",
    "    similarity_df = pd.DataFrame({'user_id':users, 'similarity':similarity,'n_articles':n_articles})\n",
    "\n",
    "    return similarity_df.sort_values(by = ['similarity','n_articles'], ascending = False).index.to_list()\n",
    "    return neighbors_df # Return the dataframe specified in the doc_string\n",
    "\n",
    "\n",
    "def user_user_recs_part2(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions \n",
    "    before choosing those with fewer total interactions. \n",
    "   \n",
    "    '''\n",
    "    # Your code here\n",
    "    similar_users = find_similar_users(user_id)\n",
    "    user_article_ids = get_user_articles(user_id)[0]\n",
    "    recs = []\n",
    "    n_user=1\n",
    "    nrecs  = 0\n",
    "    cond = True\n",
    "    while cond:\n",
    "        current_ids=get_user_articles(similar_users[n_user])[0]\n",
    "        u1 = set(user_article_ids)\n",
    "        u2 = set(current_ids)\n",
    "        setdif= list(u2 - u1)\n",
    "        for e in setdif:\n",
    "            recs.append(e)\n",
    "            nrecs = nrecs+1\n",
    "            if nrecs == m:\n",
    "                cond = False\n",
    "                break\n",
    "        n_user = n_user+1\n",
    "    \n",
    "    resorted_recs = []\n",
    "    # sort articles by most popular first\n",
    "    for ind in df.groupby('article_id').count().sort_values('title',ascending=False).index.to_list():\n",
    "        \n",
    "        if str(ind) in recs:\n",
    "            resorted_recs.append(str(ind))\n",
    "    rec_names = get_article_names(resorted_recs)   \n",
    "    \n",
    "    return resorted_recs, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 recommendations for user 20 are the following article ids:\n",
      "['1429.0', '1185.0', '1305.0', '1336.0', '1165.0', '124.0', '1163.0', '1400.0', '164.0', '278.0']\n",
      "\n",
      "The top 10 recommendations for user 20 are the following article names:\n",
      "['use deep learning for image classification', 'analyze precipitation data', 'gosales transactions for naive bayes model', 'learn tensorflow and deep learning together and now!', 'learn basics about notebooks and apache spark', 'classify tumors with machine learning', 'deep learning trends and an example', 'python machine learning: scikit-learn tutorial', 'analyze open data sets with spark & pixiedust', 'uci ml repository: chronic kidney disease data set']\n"
     ]
    }
   ],
   "source": [
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "rec_ids, rec_names = user_user_recs_part2(20, 10)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Use your functions from above to correctly fill in the solutions to the dictionary below.  Then test your dictionary against the solution.  Provide the code you need to answer each following the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tests with a dictionary of results\n",
    "\n",
    "user1_most_sim =find_similar_users(1) [1]# Find the user that is most similar to user 1 \n",
    "user131_10th_sim = find_similar_users(131)[10] # Find the 10th most similar user to user 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-bd0702018110>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m }\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msol_5_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msol_5_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\IBM_recommendations\\project_tests.py\u001b[0m in \u001b[0;36msol_5_test\u001b[1;34m(sol_5_dict)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msol_5_dict_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msol_5_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msol_5_dict_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Oops!  Looks like there is a mistake with the {} key in your dictionary.  The answer should be {}.  Try again.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "## Dictionary Test Here\n",
    "sol_5_dict = {\n",
    "    'The user that is most similar to user 1.': user1_most_sim, \n",
    "    'The user that is the 10th most similar to user 131': user131_10th_sim,\n",
    "}\n",
    "\n",
    "t.sol_5_test(sol_5_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` If we were given a new user, which of the above functions would you be able to use to make recommendations?  Explain.  Can you think of a better way we might make recommendations?  Use the cell below to explain a better method for new users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would be able to use recommendations using only the top articles ( the most interacted articles). A better method would be to explore which article do new users tend to read first, and provide those in the recommendations. We could also rely on certain filters that users provide to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7.` Using your existing functions, provide the top 10 recommended articles you would provide for the a new user below.  You can test your function against our thoughts to make sure we are all on the same page with how we might make a recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user = '0.0'\n",
    "\n",
    "# What would your recommendations be for this new user '0.0'?  As a new user, they have no observed articles.\n",
    "# Provide a list of the top 10 article ids you would give to \n",
    "new_user_recs = get_top_article_ids(10) # Your recommendations here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "assert set(new_user_recs) == set(['1314.0','1429.0','1293.0','1427.0','1162.0','1364.0','1304.0','1170.0','1431.0','1330.0']), \"Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\n",
    "\n",
    "print(\"That's right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Content-Recs\">Part IV: Content Based Recommendations (EXTRA - NOT REQUIRED)</a>\n",
    "\n",
    "Another method we might use to make recommendations is to perform a ranking of the highest ranked articles associated with some term.  You might consider content to be the **doc_body**, **doc_description**, or **doc_full_name**.  There isn't one way to create a content based recommendation, especially considering that each of these columns hold content related information.  \n",
    "\n",
    "`1.` Use the function body below to create a content based recommender.  Since there isn't one right answer for this recommendation tactic, no test functions are provided.  Feel free to change the function inputs if you decide you want to try a method that requires more input values.  The input values are currently set with one idea in mind that you may use to make content based recommendations.  One additional idea is that you might want to choose the most popular recommendations that meet your 'content criteria', but again, there is a lot of flexibility in how you might make these recommendations.\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_content_recs():\n",
    "    '''\n",
    "    INPUT:\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now that you have put together your content-based recommendation system, use the cell below to write a summary explaining how your content based recommender works.  Do you see any possible improvements that could be made to your function?  Is there anything novel about your content based recommender?\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write an explanation of your content based recommendation system here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use your content-recommendation system to make recommendations for the below scenarios based on the comments.  Again no tests are provided here, because there isn't one right answer that could be used to find these content based recommendations.\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make recommendations for a brand new user\n",
    "\n",
    "\n",
    "# make a recommendations for a user who only has interacted with article id '1427.0'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Matrix-Fact\">Part V: Matrix Factorization</a>\n",
    "\n",
    "In this part of the notebook, you will build use matrix factorization to make article recommendations to the users on the IBM Watson Studio platform.\n",
    "\n",
    "`1.` You should have already created a **user_item** matrix above in **question 1** of **Part III** above.  This first question here will just require that you run the cells to get things set up for the rest of **Part V** of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix here\n",
    "user_item_matrix = pd.read_pickle('user_item_matrix.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>1004.0</th>\n",
       "      <th>1006.0</th>\n",
       "      <th>1008.0</th>\n",
       "      <th>101.0</th>\n",
       "      <th>1014.0</th>\n",
       "      <th>1015.0</th>\n",
       "      <th>1016.0</th>\n",
       "      <th>...</th>\n",
       "      <th>977.0</th>\n",
       "      <th>98.0</th>\n",
       "      <th>981.0</th>\n",
       "      <th>984.0</th>\n",
       "      <th>985.0</th>\n",
       "      <th>986.0</th>\n",
       "      <th>990.0</th>\n",
       "      <th>993.0</th>\n",
       "      <th>996.0</th>\n",
       "      <th>997.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0  100.0  1000.0  1004.0  1006.0  1008.0  101.0  1014.0  1015.0  \\\n",
       "user_id                                                                         \n",
       "1           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "2           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "3           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "4           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "5           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "\n",
       "article_id  1016.0  ...  977.0  98.0  981.0  984.0  985.0  986.0  990.0  \\\n",
       "user_id             ...                                                   \n",
       "1              0.0  ...    0.0   0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "2              0.0  ...    0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3              0.0  ...    1.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4              0.0  ...    0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "5              0.0  ...    0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "article_id  993.0  996.0  997.0  \n",
       "user_id                          \n",
       "1             0.0    0.0    0.0  \n",
       "2             0.0    0.0    0.0  \n",
       "3             0.0    0.0    0.0  \n",
       "4             0.0    0.0    0.0  \n",
       "5             0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick look at the matrix\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` In this situation, you can use Singular Value Decomposition from [numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html) on the user-item matrix.  Use the cell to perform SVD, and explain why this is different than in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SVD on the User-Item Matrix Here\n",
    "\n",
    "u, s, vt =np.linalg.svd(user_item_matrix) # use the built in to get the three matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are interested only if a user has interacted with an article (thus it is impossible to have a NaN, which causes the algorithm to diverge)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now for the tricky part, how do we choose the number of latent features to use?  Running the below cell, you can see that as the number of latent features increases, we obtain a lower error rate on making predictions for the 1 and 0 values in the user-item matrix.  Run the cell below to get an idea of how the accuracy improves as we increase the number of latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "    \n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` From the above, we can't really be sure how many features to use, because simply having a better way to predict the 1's and 0's of the matrix doesn't exactly give us an indication of if we are able to make good recommendations.  Instead, we might split our dataset into a training and test set of data, as shown in the cell below.  \n",
    "\n",
    "Use the code from question 3 to understand the impact on accuracy of the training and test sets of data with different numbers of latent features. Using the split below: \n",
    "\n",
    "* How many users can we make predictions for in the test set?  \n",
    "* How many users are we not able to make predictions for because of the cold start problem?\n",
    "* How many articles can we make predictions for in the test set?  \n",
    "* How many articles are we not able to make predictions for because of the cold start problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juggernaut\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train = df.head(40000)\n",
    "df_test = df.tail(5993)\n",
    "\n",
    "def create_test_and_train_user_item(df_train, df_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df_train - training dataframe\n",
    "    df_test - test dataframe\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item_train - a user-item matrix of the training dataframe \n",
    "                      (unique users for each row and unique articles for each column)\n",
    "    user_item_test - a user-item matrix of the testing dataframe \n",
    "                    (unique users for each row and unique articles for each column)\n",
    "    test_idx - all of the test user ids\n",
    "    test_arts - all of the test article ids\n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    tmpdf = df_train.copy()\n",
    "    tmpdf.fillna(value =0, inplace = True)\n",
    "    tmpdf['title'].iloc[:]=1\n",
    "    user_item_train = tmpdf.pivot_table(index = 'user_id', columns = 'article_id',aggfunc = 'max', values='title')\n",
    "    user_item_train.fillna(value=0, inplace= True)\n",
    "    del tmpdf\n",
    "    \n",
    "    tmpdf = df_test.copy()\n",
    "    tmpdf.fillna(value=0, inplace = True)\n",
    "    tmpdf['title'].iloc[:]=1\n",
    "    user_item_test = tmpdf.pivot_table(index = 'user_id', columns = 'article_id',aggfunc = 'max', values='title')\n",
    "    user_item_test.fillna(value=0, inplace= True)\n",
    "    \n",
    "    test_idx = list(set(user_item_test.index.to_list()))\n",
    "    test_arts = list(set(user_item_test.columns.to_list()))\n",
    "    \n",
    "    return user_item_train, user_item_test, test_idx, test_arts\n",
    "\n",
    "user_item_train, user_item_test, test_idx, test_arts = create_test_and_train_user_item(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users we can make a prediction on 20\n",
      "users we cannot make a prediction on 662\n",
      "articles we can make a prediction on 574\n",
      "articles we cannot make a prediction on 0\n"
     ]
    }
   ],
   "source": [
    "ind_train = set(user_item_train.index.to_list())\n",
    "ind_test = set(user_item_test.index.to_list())\n",
    "print(\"users we can make a prediction on\", len(ind_test.intersection(ind_train)))\n",
    "print(\"users we cannot make a prediction on\", len(ind_test-ind_train))\n",
    "articles_train = set(user_item_train.columns.to_list())\n",
    "articles_test = set(user_item_test.columns.to_list())\n",
    "print(\"articles we can make a prediction on\", len(articles_test.intersection(articles_train)))\n",
    "print(\"articles we cannot make a prediction on\", len(articles_test - articles_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome job!  That's right!  All of the test movies are in the training data, but there are only 20 test users that were also in the training set.  All of the other users that are in the test set we have no data on.  Therefore, we cannot make predictions for these users using SVD.\n"
     ]
    }
   ],
   "source": [
    "# Replace the values in the dictionary below\n",
    "a = 662 \n",
    "b = 574 \n",
    "c = 20 \n",
    "d = 0 \n",
    "\n",
    "\n",
    "sol_4_dict = {\n",
    "    'How many users can we make predictions for in the test set?':c, # letter here, \n",
    "    'How many users in the test set are we not able to make predictions for because of the cold start problem?':a, # letter here, \n",
    "    'How many movies can we make predictions for in the test set?':b, # letter here,\n",
    "    'How many movies in the test set are we not able to make predictions for because of the cold start problem?':d # letter here\n",
    "}\n",
    "\n",
    "t.sol_4_test(sol_4_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Now use the **user_item_train** dataset from above to find U, S, and V transpose using SVD. Then find the subset of rows in the **user_item_test** dataset that you can predict using this matrix decomposition with different numbers of latent features to see how many features makes sense to keep based on the accuracy on the test data. This will require combining what was done in questions `2` - `4`.\n",
    "\n",
    "Use the cells below to explore how well SVD works towards making predictions for recommendations on the test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit SVD on the user_item_train matrix\n",
    "u_train, s_train, vt_train = np.linalg.svd(user_item_train)# fit svd similar to above then use the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on latent_features =  10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use these cells to see how well you can use the training \n",
    "# decomposition to predict on test data\n",
    "\n",
    "# Create series of users and article in the right order\n",
    "num_latent_feats = [10]#np.arange(10,100,20)\n",
    "user_ids_series = np.array(user_item_test.index)\n",
    "article_ids_series = np.array(user_item_test.columns)\n",
    "sum_errs=[]\n",
    "users_wissues=[]\n",
    "for k in num_latent_feats:\n",
    "    estimated = user_item_test.copy()\n",
    "    print('running on latent_features = ',k)\n",
    "    for user in user_ids_series:\n",
    "        try:\n",
    "            user_row = np.where(user_ids_series == user)[0][0]\n",
    "        except:\n",
    "            users_wissues.append(user_id)\n",
    "            continue\n",
    "        for article in article_ids_series:\n",
    "            # User row and Movie Column\n",
    "            try:\n",
    "                article_col = np.where(article_ids_series == article)[0][0]\n",
    "            except:\n",
    "                continue\n",
    "            # Take dot product of that row and column in U and V to make prediction\n",
    "            #pred = np.dot(u_train[user_row, :], movie_matrix[:, movie_col])\n",
    "            s_new, u_new, vt_new = np.diag(s[:k]), u[user_row, :k], vt[:k, article_col]\n",
    "    \n",
    "            # take dot product\n",
    "            pred = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "            estimated.loc[user,article] = pred\n",
    "            # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(estimated, user_item_test)\n",
    "    \n",
    "            # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)  \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`6.` Use the cell below to comment on the results you found in the previous question. Given the circumstances of your results, discuss what you might do to determine if the recommendations you make with any of the above recommendation systems are an improvement to how users currently find articles? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='conclusions'></a>\n",
    "### Extras\n",
    "Using your workbook, you could now save your recommendations for each user, develop a class to make new predictions and update your results, and make a flask app to deploy your results.  These tasks are beyond what is required for this project.  However, from what you learned in the lessons, you certainly capable of taking these tasks on to improve upon your work here!\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "> Congratulations!  You have reached the end of the Recommendations with IBM project! \n",
    "\n",
    "> **Tip**: Once you are satisfied with your work here, check over your report to make sure that it is satisfies all the areas of the [rubric](https://review.udacity.com/#!/rubrics/2322/view). You should also probably remove all of the \"Tips\" like this one so that the presentation is as polished as possible.\n",
    "\n",
    "\n",
    "## Directions to Submit\n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Recommendations_with_IBM.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
